package com.agp.demo.es;

/**
 * Elasticsearch是实时的分布式搜索分析引擎，内部使用Lucene做索引与搜索。
 *
 * 按官方的描述，集群规模支持“上百”个节点，
 *
 * 目前我们认为ES适合中等数据量的业务，不适合存储海量数据。
 *
 * Lucene是Java语言编写的全文搜索框架，用于处理纯文本的数据，
 * 但它只是一个库，提供建立索引、执行搜索等接口，
 * 但不包含分布式服务，这些正是 ES 做的
 *
 * 基于ES，你可以很容易地搭建自己的搜索引擎，用于分析日志，
 * 或者配合开源爬虫建立某个垂直领域的搜索引擎。
 *
 * ES 还提供了大量的聚合功能，所以它不单单是一个搜索引擎，
 * 还可以进行数据分析、统计，生成指标数据。
 *
 * 一般使用 JSON 作为文档的序列化格式，文档可以有很多字段，
 * 在创建索引的时候，我们需要描述文档中每个字段的数据类型，
 * 并且可能需要指定不同的分析器
 *
 * 在存储结构上，由_index、_type和_id唯一标识一个文档。
 *
 * _index指向一个或多个物理分片的逻辑命名空间，
 * _type类型用于区分同一个集合中的不同细分，
 * 在不同的细分中，数据的整体模式是相同或相似的，不适合完全不同类型的数据。
 * 多个_type可以在相同的索引中存在，只要它们的字段不冲突即可
 *
 * _id文档标记符由系统自动生成或使用者提供。
 *
 * 在ES 6.x版本中，一个索引只允许存在一个_type，未来的7.x版本将完全删除_type的概念。
 *
 * 分片（shard）
 *
 *      在分布式系统中，单机无法存储规模巨大的数据，
 *      要依靠大规模集群处理和存储这些数据，
 *      一般通过增加机器数量来提高系统水平扩展能力。
 *      因此，需要将数据分成若干小块分配到各个机器上。
 *      然后通过某种路由策略找到某个数据块所在的位置。
 *
 *      数据分片以提高水平扩展能力，分布式存储中还会把数据复制成多个副本
 *
 *      多数据副本也带来了一致性的问题：部分副本写成功，部分副本写失败
 *
 *      为了应对 并发 更新问题，ES将数据副本分为主从两部分，
 *      即:
 *      主分片（primary shard）
 *      副分片（replica shard）
 *
 *      分片（shard）是底层的基本读写单元，分片的目的是分割巨大索引，
 *      让读写可以并行操作，由多台机器共同完成。
 *      读写请求最终落到某个分片上，分片可以独立执行读写工作。
 *      ES利用分片将数据分发到集群内各处。
 *      分片是数据的容器，文档保存在分片内，不会跨分片存储。
 *      分片又被分配到集群内的各个节点里。
 *      当集群规模扩大或缩小时，ES 会自动在各节点中迁移分片，
 *      使数据仍然均匀分布在集群里。
 *
 *
 *   索引和分片的关系：
 *
 *      一个ES索引包含很多分片，
 *          一个分片是一个Lucene的索引，它本身就是一个完整的搜索引擎，
 *          可以独立执行建立索引和搜索任务。 1->n
 *      Lucene索引又由很多 分段组成，每个分段都是一个 倒排索引。1->n ->n*m
 *      ES每次“refresh”都会生成一个新的分段，
 *          其中包含若干文档的数据。
 *          在每个分段内部，文档的不同字段被单独建立索引。
 *      每个字段的值由若干词（Term）组成，1->n ->n*m -> n*m*t
 *      Term是原文本内容经过分词器处理和语言处理后的最终结果
 *
 *
 *
 *   索引建立的时候就需要确定好主分片数
 *      我们仍然需要在一开始就尽量规划好主分片数量：
 *          先依据硬件情况定好单个分片容量，
 *          然后依据业务场景预估数据量和增长量，
 *          再除以单个分片容量。
 *
 *   分片数不够时，可以考虑新建索引，
 *   搜索1个有着50个分片的索引
 *   与搜索50个每个都有1个分片的索引完全等价
 *
 *   索引别名 就像一个快捷方式或软链接，
     *   不同的是它可以指向一个或多个索引。
     *   可以用于实现索引分组，
     *   或者索引间的无缝切换。
 *
 *   周期性创建新索引带来的一个新问题是集群整体分片数量较多，
 *   集群管理的总分片数越多压力就越大。
 *   在每天生成一个新索引的场景中，可能某天产生的数据量很小，
 *   实际上不需要这么多分片，甚至一个就够。
 *   这时，可以使用_shrink API来缩减主分片数量，降低集群负载。
 *
 *
 *   为文档建立索引，使其每个字段都可以被搜索，
 *   通过关键词检索文档内容，会使用倒排索引的数据结构。
 *   倒排索引一旦被写入文件后就具有不变性，不变性具有许多好处：
 *      对文件的访问不需要加锁，
 *      读取索引时可以被文件系统缓存等。
 *
 *   那么索引如何更新，让新添加的文档可以被搜索到？
 *      答案是使用更多的索引，
 *      新增内容并写到一个新的倒排索引中，
 *      查询时，每个倒排索引都被轮流查询， n*m个索引要查询
 *      查询完再对结果进行合并。
 *
 *    每次内存缓冲的数据被写入文件时，会产生一个新的Lucene段，每个段都是一个倒排索引。
 *    在一个记录元信息的文件中描述了当前Lucene索引都含有哪些分段。
 *
 *   由于分段的不变性，更新、删除等操作实际上是
 *   将数据标记为删除，记录到单独的位置，这种方式称为标记删除。
 *   因此删除部分数据不会释放磁盘空间。
 *
 *   ES正是利用这种特性实现了近实时搜索。
 *   每秒产生一个新分段，新段先写入文件系统缓存，
 *   但稍后再执行flush刷盘操作，写操作很快会执行完，
 *   一旦写成功，就可以像其他文件一样被打开和读取了
 *
 *   每次对ES进行操作时均记录事务日志，
 *   当ES启动的时候，重放translog中所有在最后一次提交后发生的变更操作
 *
 *   段合并
 *      每秒清空一次写缓冲，将这些数据写入文件，这个过程称为refresh，
 *      每次refresh会创建一个新的Lucene 段。
 *      但是分段数量太多会带来较大的麻烦，
 *      每个段都会消耗文件句柄、内存。
 *      每个搜索请求都需要轮流检查每个段，查询完再对结果进行合并
 *
 *      所以段越多，搜索也就越慢。
 *      因此需要通过一定的策略将这些较小的段合并为大的段，
 *          常用的方案是选择 大小相似 的分段进行 合并
 *
 *       在合并过程中，标记为删除的数据不会写入新分段，
 *       当合并过程结束，旧的分段数据被删除，
 *       标记删除的数据才从磁盘删除。
 *
 *
 *
 *
 *
 *
 *
 *
 */
public class 概念和原理 {
}
