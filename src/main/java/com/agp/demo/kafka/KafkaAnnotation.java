package com.agp.demo.kafka;

/**
 * 高吞吐原因：
 * 1.顺序写
 * 2.zero copy
 * 3.mmp  memory mapped files 物理内存映射，虚拟内存，page直接写入磁盘
 * 4.partition 文件分区，每个topic可以分散到不同的分区队列中写入。
 * 5. 分段日志，每个data文件，对应有index文件，用户消费时，方便查询offset。
 * 6. 批量压缩，降低磁盘IO消耗 gzip
 * 7.批量读写 不是单条读写
 */
public class KafkaAnnotation {
    /*幂等性消费端控制： 消费时，加入到内存set中，中断后，再次消费查看set中是否已存在*/
    /*生产端，retry发送。  brokers ACK设置为-1 所有的副本都收到后再进行发送。*/

    /*broker本身：replica必须大于一、min.insync.replica必须大于1、ack=all 所有的follower必须确认收到*/


/*为了与首领保持同步，跟随者向首领发送获取数据的请求
，这种请求与消费者为了读取消息而发送的请求是一样的。
首领将相应消息发送给跟随者。
请求消息里包含了跟随者想要获取消息的偏移量，
而且这些偏移量总是有序的。

一个跟随者副本先请求消息1，
接着请求消息2，然后请求消息3，
在收到这3个请求的相应之前，它是不会发送第四个请求消息的。
如果跟随者发送了请求消息4，
那么首领就会知道它已经收到了前面3个请求的相应。
通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度*/


/**
 * afka在0.11.0.0在引入幂等性概念的同时也引入了事务的概念。
 * 一般来说默认消费者消费的信息级别是read_uncommited数据；
 * 这有可能读取到事务失败的数据，所以在开启生产者事务之后，
 * 需要用户设置消费者的事务隔离级别
 *
 *
 * SpringBoot 开始kafka事务： application.yml
 * producer:
 * 	  #开启事务，当开启时retries必须>0 acks必须为all
 *       transaction-id-prefix: transaction
 *       # 写入失败时，重试次数。当leader节点失效，
 *       一个repli节点会替代成为leader节点，此时可能出现写入失败，
 *       # 当retris为0时，produce不会重复。retirs重发，
 *       此时repli节点完全成为leader节点，不会产生消息丢失。
 *       retries: 1
 *       #procedure要求leader在考虑完成请求之前收到的确认数，
 *       用于控制发送记录在服务端的持久化，其值可以为如下：
 *       #acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，
 *       该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，
 *       并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
 *       #acks = 1 这意味着leader会将记录写入其本地日志，
 *       但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，
 *       如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
 *       #acks = all 这意味着leader将等待完整的同步副本集以确认记录，
 *       这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，
 *       这是最强有力的保证，这相当于acks = -1的设置。
 *       #可以设置的值为：all, -1, 0, 1
 *       acks: all
 *
 * */
}
