package com.agp.demo.kafka;

/**
 * 一个消费者可以订阅一个或多个主题，
 * 可以以集合的形式订阅多个主题，也可以以正则表达式的形式订阅特定模式的主题
 *
 *位移提交 offset commit
 * 对于Kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。
 * 对于消费者而言，它也有一个offset的概念，消费者使用offset来表示消费到分区中某个消息所在的位置。
 *
 *
 * 在每次调用poll（）方法时，它返回的是还没有被消费过的消息集
 * （当然这个前提是消息已经存储在Kafka 中了，并且暂不考虑异常情况的发生）
 * ，要做到这一点，就需要记录上一次消费时的消费位移。
 * 并且这个消费位移必须做持久化保存，
 * 而不是单单保存在内存中，
 * 否则消费者重启之后就无法知晓之前的消费位移。
 *
 * 在旧消费者客户端中，消费位移是存储在ZooKeeper中的。
 * 而在新消费者客户端中，消费位移存储在Kafka内部的
 * 主题__consumer_offsets中。
 *
 * 这里把将消费位移存储起来（持久化）的动作称为“提交”，
 * 消费者在消费完消息之后需要执行消费位移的提交
 *
 *
 * 当前消费者需要提交的消费位移并不是 x，
 * 而是 x+1，对应于图3-6中的position，
 * 它表示下一条需要拉取的消息的位置。
 *
 * 在消费者中还有一个committed offset的概念，它表示已经提交过的消费位移。
 *
 * KafkaConsumer 类提供了 position（TopicPartition）和 committed（TopicPartition）
 * 两个方法来分别获取上面所说的position和committed offset的值。
 *
 *
 * 在 Kafka 中默认的消费位移的提交方式是自动提交，
 * 这个由消费者客户端
 * 参数enable.auto.commit配置，默认值为 true。
 *
 * 当然这个默认的自动提交不是每消费一条消息就提交一次，
 * 而是定期提交，这个定期的周期时间由客户端参数auto.commit.interval.ms配置，默认值为5秒，
 * 此参数生效的前提是enable.auto.commit参数为true。
 *
 * 在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。
 * 自动位移提交的动作是在poll（）方法的逻辑里完成的，
 * 在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，
 * 如果可以，那么就会提交上一次轮询的位移。
 *
 * 自动提交消费位移会导致重复消费和消息丢失的问题
 *
 * 开启手动提交功能的前提是消费者客户端参数enable.auto.commit配置为false，
 *
 * 手动提交可以细分为同步提交和异步提交，
 * 对应于 KafkaConsumer 中的 commitSync（）和commitAsync（）两种类型的方法
 *
 *
 * commitAsync（）提交的时候同样会有失败的情况发生
 * ，那么我们应该怎么处理呢？读者有可能想到的是重试，
 * 问题的关键也就在这里了。如果某一次异步提交的消费位移为 x，
 * 但是提交失败了，然后下一次又异步提交了消费位移为 x+y，这次成功了。
 * 如果这里引入了重试机制，
 * 前一次的异步提交的消费位移在重试的时候提交成功了，
 * 那么此时的消费位移又变为了 x。如果此时发生异常（或者再均衡），
 * 那么恢复之后的消费者（或者新的消费者）就会从x处开始消费消息
 * ，这样就发生了重复消费的问题。
 *
 *
 * 我们可以设置一个递增的序号来维护异步提交的顺序，
 * 每次位移提交之后就增加序号相对应的值。
 * 在遇到位移提交失败需要重试的时候，可以检查所提交的位移和序号的值的大小，
 * 如果前者小于后者，则说明有更大的位移已经提交了，不需要再进行本次重试；
 * 如果两者相同，则说明可以进行重试提交。
 * 除非程序编码错误，否则不会出现前者大于后者的情况。
 *
 *
 *
 *
 *
 *
 */
public class Consumer开发 {
}
